{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Python_DeepLearning_Pytorch - part1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNr/JwkbkH/jjNYEEqveQ6M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UYsEiNYr2aSz"},"source":["# Python_DeepLearning_Pytorch - part1"]},{"cell_type":"markdown","metadata":{"id":"HZqQX-ow2l4e"},"source":["#### 딥러닝과 파이토치와 관련된 기본적인 내용을 정리하였습니다. 파이썬 딥러닝 파이토치(이경택, 방성수, 안상주 지음)을 참고하였습니다. \n","#### GPU 사용을 위해서 google colab을 활용하여 작성하였습니다."]},{"cell_type":"markdown","metadata":{"id":"FKtx0Ph4279-"},"source":["## 1. 파이토치 기초 \n","### 1.1 텐서\n","#### - 텐서란 데이터를 표현하는 단위이다. \n","#### 1.1.1 Scalar"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrRQIJC73LHF","executionInfo":{"status":"ok","timestamp":1621834659414,"user_tz":-540,"elapsed":257,"user":{"displayName":"Minguk Kim","photoUrl":"","userId":"04080639930041592482"}},"outputId":"3a47a93a-36b1-422b-c75c-e76efc7caf32"},"source":["import torch\n","\n","scalar1 = torch.tensor([1.])\n","print(scalar1)\n","print(\"------------------------------------------\")\n","\n","scalar2 = torch.tensor([3.])\n","print(scalar2)\n","print(\"------------------------------------------\")\n","\n","add_scalar = scalar1 + scalar2\n","print(add_scalar)\n","print(\"------------------------------------------\")\n","\n","sub_scalar = scalar1 - scalar2\n","print(sub_scalar)\n","print(\"------------------------------------------\")\n","\n","mul_scalar = scalar1 * scalar2\n","print(mul_scalar)\n","print(\"------------------------------------------\")\n","\n","div_scalar = scalar1 / scalar2\n","print(div_scalar)\n","print(\"------------------------------------------\")\n","\n","print(torch.add(scalar1, scalar2))\n","print(\"------------------------------------------\")\n","\n","print(torch.sub(scalar1, scalar2))\n","print(\"------------------------------------------\")\n","\n","print(torch.mul(scalar1, scalar2))\n","print(\"------------------------------------------\")\n","\n","print(torch.div(scalar1, scalar2))\n","print(\"------------------------------------------\")\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([1.])\n","------------------------------------------\n","tensor([3.])\n","------------------------------------------\n","tensor([4.])\n","------------------------------------------\n","tensor([-2.])\n","------------------------------------------\n","tensor([3.])\n","------------------------------------------\n","tensor([0.3333])\n","------------------------------------------\n","tensor([4.])\n","------------------------------------------\n","tensor([-2.])\n","------------------------------------------\n","tensor([3.])\n","------------------------------------------\n","tensor([0.3333])\n","------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ErL0b3Cs4QnR"},"source":["#### 1.1.2 Vector"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ol2V5ue03QDk","executionInfo":{"status":"ok","timestamp":1621834845167,"user_tz":-540,"elapsed":333,"user":{"displayName":"Minguk Kim","photoUrl":"","userId":"04080639930041592482"}},"outputId":"4dfeafc1-38cb-46d1-cc86-45fa5027fe3a"},"source":["vector1 = torch.tensor([1.,2.,3.])\n","print(vector1)\n","print(\"------------------------------------------\")\n","\n","vector2 = torch.tensor([4.,5.,6.])\n","print(vector2)\n","print(\"------------------------------------------\")\n","\n","add_vector = vector1 + vector2\n","print(add_vector)\n","print(\"------------------------------------------\")\n","\n","sub_vector = vector1 - vector2\n","print(sub_vector)\n","print(\"------------------------------------------\")\n","\n","mul_vector = vector1 * vector2\n","print(mul_vector)\n","print(\"------------------------------------------\")\n","\n","div_vector = vector1 / vector2\n","print(div_vector)\n","print(\"------------------------------------------\")\n","\n","print(torch.add(vector1, vector2))\n","print(\"------------------------------------------\")\n","\n","print(torch.sub(vector1, vector2))\n","print(\"------------------------------------------\")\n","\n","print(torch.mul(vector1, vector2))\n","print(\"------------------------------------------\")\n","\n","print(torch.div(vector1, vector2))\n","print(\"------------------------------------------\")\n","\n","# 내적\n","print(torch.dot(vector1, vector2))\n","print(\"------------------------------------------\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["tensor([1., 2., 3.])\n","------------------------------------------\n","tensor([4., 5., 6.])\n","------------------------------------------\n","tensor([5., 7., 9.])\n","------------------------------------------\n","tensor([-3., -3., -3.])\n","------------------------------------------\n","tensor([ 4., 10., 18.])\n","------------------------------------------\n","tensor([0.2500, 0.4000, 0.5000])\n","------------------------------------------\n","tensor([5., 7., 9.])\n","------------------------------------------\n","tensor([-3., -3., -3.])\n","------------------------------------------\n","tensor([ 4., 10., 18.])\n","------------------------------------------\n","tensor([0.2500, 0.4000, 0.5000])\n","------------------------------------------\n","tensor(32.)\n","------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"STTytE6l4-Jh"},"source":["#### 1.1.3 행렬"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcUiq1T940cy","executionInfo":{"status":"ok","timestamp":1621835084857,"user_tz":-540,"elapsed":401,"user":{"displayName":"Minguk Kim","photoUrl":"","userId":"04080639930041592482"}},"outputId":"c0872a72-a5ed-4d34-b1e1-f57c507d36f2"},"source":["matrix1 = torch.tensor([[1., 2.], [3., 4.]])\n","print(matrix1)\n","print(\"------------------------------------------\")\n","\n","matrix2 = torch.tensor([[5.,6.], [7.,8.]])\n","print(matrix2)\n","print(\"------------------------------------------\")\n","\n","sum_matrix = matrix1 + matrix2\n","print(sum_matrix)\n","print(\"------------------------------------------\")\n","\n","sub_matrix = matrix1 - matrix2\n","print(sub_matrix)\n","print(\"------------------------------------------\")\n","\n","mul_matrix = matrix1 * matrix2\n","print(mul_matrix)\n","print(\"------------------------------------------\")\n","\n","div_matrix = matrix1 / matrix2\n","print(div_matrix)\n","print(\"------------------------------------------\")\n","\n","print(torch.add(matrix1, matrix2))\n","print(\"------------------------------------------\")\n","\n","print(torch.sub(matrix1, matrix2))\n","print(\"------------------------------------------\")\n","\n","print(torch.mul(matrix1, matrix2))\n","print(\"------------------------------------------\")\n","\n","print(torch.div(matrix1, matrix2))\n","print(\"------------------------------------------\")\n","\n","# 행렬곱\n","print(torch.matmul(matrix1, matrix2))\n","print(\"------------------------------------------\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([[1., 2.],\n","        [3., 4.]])\n","------------------------------------------\n","tensor([[5., 6.],\n","        [7., 8.]])\n","------------------------------------------\n","tensor([[ 6.,  8.],\n","        [10., 12.]])\n","------------------------------------------\n","tensor([[-4., -4.],\n","        [-4., -4.]])\n","------------------------------------------\n","tensor([[ 5., 12.],\n","        [21., 32.]])\n","------------------------------------------\n","tensor([[0.2000, 0.3333],\n","        [0.4286, 0.5000]])\n","------------------------------------------\n","tensor([[ 6.,  8.],\n","        [10., 12.]])\n","------------------------------------------\n","tensor([[-4., -4.],\n","        [-4., -4.]])\n","------------------------------------------\n","tensor([[ 5., 12.],\n","        [21., 32.]])\n","------------------------------------------\n","tensor([[0.2000, 0.3333],\n","        [0.4286, 0.5000]])\n","------------------------------------------\n","tensor([[19., 22.],\n","        [43., 50.]])\n","------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5X0JjnRr58r4"},"source":["#### 1.1.4 텐서\n","#### - 텐서는 2차원 이상의 배열이라고 생각할 수 있다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yx1U6fKo5MwL","executionInfo":{"status":"ok","timestamp":1621835336830,"user_tz":-540,"elapsed":501,"user":{"displayName":"Minguk Kim","photoUrl":"","userId":"04080639930041592482"}},"outputId":"7d4ca0f2-a17d-44ed-ca04-12fc6b9cb787"},"source":["tensor1 = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n","print(tensor1)\n","print(\"------------------------------------------\")\n","\n","tensor2 = torch.tensor([[[9., 10.], [11., 12]], [[13., 14.], [15., 16.]]])\n","print(tensor2)\n","print(\"------------------------------------------\")\n","\n","sum_tensor = tensor1 + tensor2\n","print(sum_tensor)\n","print(\"------------------------------------------\")\n","\n","sub_tensor = tensor1- tensor2\n","print(sub_tensor)\n","print(\"------------------------------------------\")\n","\n","mul_tensor = tensor1*tensor2\n","print(mul_tensor)\n","print(\"------------------------------------------\")\n","\n","div_tensor = tensor1 / tensor2\n","print(div_tensor)\n","print(\"------------------------------------------\")\n","\n","print(torch.add(tensor1, tensor2))\n","print(\"------------------------------------------\")\n","\n","print(torch.sub(tensor1, tensor2))\n","print(\"------------------------------------------\")\n","\n","print(torch.mul(tensor1, tensor2))\n","print(\"------------------------------------------\")\n","\n","print(torch.div(tensor1, tensor2))\n","print(\"------------------------------------------\")\n","\n","# 텐서 행렬 곱\n","print(torch.matmul(tensor1, tensor2))\n","print(\"------------------------------------------\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["tensor([[[1., 2.],\n","         [3., 4.]],\n","\n","        [[5., 6.],\n","         [7., 8.]]])\n","------------------------------------------\n","tensor([[[ 9., 10.],\n","         [11., 12.]],\n","\n","        [[13., 14.],\n","         [15., 16.]]])\n","------------------------------------------\n","tensor([[[10., 12.],\n","         [14., 16.]],\n","\n","        [[18., 20.],\n","         [22., 24.]]])\n","------------------------------------------\n","tensor([[[-8., -8.],\n","         [-8., -8.]],\n","\n","        [[-8., -8.],\n","         [-8., -8.]]])\n","------------------------------------------\n","tensor([[[  9.,  20.],\n","         [ 33.,  48.]],\n","\n","        [[ 65.,  84.],\n","         [105., 128.]]])\n","------------------------------------------\n","tensor([[[0.1111, 0.2000],\n","         [0.2727, 0.3333]],\n","\n","        [[0.3846, 0.4286],\n","         [0.4667, 0.5000]]])\n","------------------------------------------\n","tensor([[[10., 12.],\n","         [14., 16.]],\n","\n","        [[18., 20.],\n","         [22., 24.]]])\n","------------------------------------------\n","tensor([[[-8., -8.],\n","         [-8., -8.]],\n","\n","        [[-8., -8.],\n","         [-8., -8.]]])\n","------------------------------------------\n","tensor([[[  9.,  20.],\n","         [ 33.,  48.]],\n","\n","        [[ 65.,  84.],\n","         [105., 128.]]])\n","------------------------------------------\n","tensor([[[0.1111, 0.2000],\n","         [0.2727, 0.3333]],\n","\n","        [[0.3846, 0.4286],\n","         [0.4667, 0.5000]]])\n","------------------------------------------\n","tensor([[[ 31.,  34.],\n","         [ 71.,  78.]],\n","\n","        [[155., 166.],\n","         [211., 226.]]])\n","------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C3F9kD5R62rF"},"source":["### 1.2 Autograd\n","#### - 파이토치를 이용해 코드를 작성할 때  Back Propagation을 이용해 파라미터를 업데이트하는 방법은 Autograd 방식으로 쉽게 구현할 수 있도록 설정돼 있다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rplhdhY_6Scr","executionInfo":{"status":"ok","timestamp":1621836535392,"user_tz":-540,"elapsed":814,"user":{"displayName":"Minguk Kim","photoUrl":"","userId":"04080639930041592482"}},"outputId":"a18160c6-4a46-4b2e-b38c-481141567031"},"source":["import torch\n","\n","if torch.cuda.is_available():   #### torch를 이용할 때 gpu를 활용할 수 있는 지 확인\n","  DEVICE = torch.device('cuda')\n","else:\n","  DEVICE = torch.devicd('cpu')\n","\n","BATCH_SIZE = 64    #### 파라미터를 업데이트할 때 계산되는 데이터의 개수 / BATCH_SIZE 수만큼 출력된 결괏값에 대한 오찻값을 계산\n","INPUT_SIZE = 1000  #### 딥러닝 모델에서 INPUT의 크기, 입력층의 노드 수 / BATCH_SIZE가 64이므로 1000 크기의 벡터 값을 64개 이용한다는 의미 / (64, 1000)\n","HIDDEN_SIZE = 100  #### 입력층의 노드 수\n","OUTPUT_SIZE = 10    #### 최종적으로 출력되는 벡터의 크기 \n","\n","x = torch.randn(BATCH_SIZE, INPUT_SIZE, device = DEVICE, dtype=torch.float, requires_grad=False) # input 이므로 gradient 계산이 필요 없음 / 파라미터 업데이트를 위해 gradient를 사용!\n","y = torch.randn(BATCH_SIZE, OUTPUT_SIZE, device = DEVICE, dtype=torch.float, requires_grad=False) \n","w1 = torch.randn(INPUT_SIZE, HIDDEN_SIZE, device = DEVICE, dtype = torch.float, requires_grad=True)\n","w2 = torch.randn(HIDDEN_SIZE, OUTPUT_SIZE, device = DEVICE, dtype=torch.float, requires_grad=True)\n","\n","learning_rate = 1e-6\n","for t in range(1,501):\n","  y_pred = x.mm(w1).clamp(min = 0).mm(w2) #### clamp(min = 0) - RELU와 같은 역할을 하는 비선형 함수\n","\n","  loss = (y_pred - y).pow(2).sum()\n","  if t % 100 == 0: \n","    print('Iteration: ', t, 'LOSS: ', loss.item())\n","  \n","  loss.backward()    #### 각 파라미터에 대해 Gradient를 계산하고 이를 통해 Back Propagation을 진행\n","\n","  with torch.no_grad():    #### 각 파리미터 값에 대해 gradient 계산한 결과를 이용해 파라미터 값을 업데이트 할 때는 해당 시점의 gradient 값을 고정한 후 업데이트를 진행\n","    w1 -= learning_rate * w1.grad    #### gradient 업데이트\n","    w2 -= learning_rate * w2.grad\n","\n","    w1.grad.zero_()    #### gradient를 초기화 해 다음 반복문을 진행할 수 있도록 gradient 값을 0으로 설정\n","    w2.grad.zero_()\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Iteration:  100 LOSS:  604.5242919921875\n","Iteration:  200 LOSS:  3.5456395149230957\n","Iteration:  300 LOSS:  0.04190492630004883\n","Iteration:  400 LOSS:  0.0008806560072116554\n","Iteration:  500 LOSS:  9.233901801053435e-05\n"],"name":"stdout"}]}]}