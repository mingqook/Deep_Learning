{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3842,
     "status": "ok",
     "timestamp": 1593193760068,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "zza1k_KOvt1P",
    "outputId": "b6067a2d-a2df-48ad-99fc-c303c314c453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                    1.5.1+cu101    \n",
      "torchsummary             1.5.1          \n",
      "torchtext                0.3.1          \n",
      "torchvision              0.6.1+cu101    \n"
     ]
    }
   ],
   "source": [
    "! pip list | grep \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJGwgEKR_GPg"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3O6ttcHKrIq"
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40011,
     "status": "ok",
     "timestamp": 1592902913534,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "1oJjy5xBJXAx",
    "outputId": "908db91e-d7e6-4d9e-aa4c-947fb94b0ceb"
   },
   "outputs": [],
   "source": [
    "# Data Setting\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  fix_length = 500,\n",
    "                  tokenize=str.split,\n",
    "                  pad_first=True,\n",
    "                  pad_token='[PAD]',\n",
    "                  unk_token='[UNK]')\n",
    "\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(text_field = TEXT, \n",
    "                                             label_field = LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39995,
     "status": "ok",
     "timestamp": 1592902913535,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "34DoliQ6mdob",
    "outputId": "ff456955-ee36-4017-d81c-9eccc8d4347a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Length : 25000\n",
      "Test Data Length : 25000\n"
     ]
    }
   ],
   "source": [
    "# Data Length\n",
    "print(f'Train Data Length : {len(train_data.examples)}')\n",
    "print(f'Test Data Length : {len(test_data.examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39980,
     "status": "ok",
     "timestamp": 1592902913536,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "3UNJJZE0mH75",
    "outputId": "720cf3db-9fc6-4ea0-90af-d1003255b9f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x197a59245f8>,\n",
       " 'label': <torchtext.data.field.LabelField at 0x197a59245c0>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Fields\n",
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38923,
     "status": "ok",
     "timestamp": 1592902913537,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "ViUZ13AM_HFQ",
    "outputId": "cd86dc6c-3ffc-4d03-c8b6-f9826986d6fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Data Sample ----\n",
      "Input : \n",
      "Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they'll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it's like to be homeless? That is Goddard Bolt's lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet's on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can't step off the sidewalk. He's given the nickname Pepto by a vagrant after it's written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They're survivors. Bolt isn't. He's not used to reaching mutual agreements like he once did when being rich where it's fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn't necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it's like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don't know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others. \n",
      "\n",
      "Label : \n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "# Data Sample\n",
    "print('---- Data Sample ----')\n",
    "print('Input : ')\n",
    "print(' '.join(vars(train_data.examples[1])['text']),'\\n')\n",
    "print('Label : ')\n",
    "print(vars(train_data.examples[1])['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pn4ddGIQLL_u"
   },
   "source": [
    "## Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpIQqgb_G41G"
   },
   "outputs": [],
   "source": [
    "def PreProcessingText(input_sentence):\n",
    "    input_sentence = input_sentence.lower() # 소문자화\n",
    "    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n",
    "    input_sentence = re.sub('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n",
    "    input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n",
    "    if input_sentence:\n",
    "        return input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cIqIf34a2SR"
   },
   "outputs": [],
   "source": [
    "for example in train_data.examples:\n",
    "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n",
    "    \n",
    "for example in test_data.examples:\n",
    "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSucMR06LR8Y"
   },
   "source": [
    "## Making Vocab & Setting Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBI0uTQUSbdt"
   },
   "outputs": [],
   "source": [
    "model_config = {'emb_type' : 'glove', 'emb_dim' : 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474879,
     "status": "ok",
     "timestamp": 1592903454602,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "8LGSnQIsAHcv",
    "outputId": "fc9cad0e-5496-4d0d-8805-277e496c60d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [09:11, 1.56MB/s]                                                                    \n",
      "100%|███████████████████████████████████████████████████████████████████████▉| 399999/400000 [00:51<00:00, 7736.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# making vocab\n",
    "TEXT.build_vocab(train_data,\n",
    "                 min_freq = 2, \n",
    "                 max_size = None,\n",
    "                 vectors = f\"glove.6B.{model_config['emb_dim']}d\")\n",
    "\n",
    "## vector list\n",
    "# charngram.100d\n",
    "# fasttext.en.300d\n",
    "# fasttext.simple.300d\n",
    "# glove.42B.300d\n",
    "# glove.840B.300d\n",
    "# glove.twitter.27B.25d\n",
    "# glove.twitter.27B.50d\n",
    "# glove.twitter.27B.100d\n",
    "# glove.twitter.27B.200d\n",
    "# glove.6B.50d\n",
    "# glove.6B.100d\n",
    "# glove.6B.200d\n",
    "# glove.6B.300d\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "model_config['vocab_size'] = len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1592903455613,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "vt7ulofTn6U4",
    "outputId": "b8092f84-74ee-44f1-c58f-c4f6dd36a980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size : 51956\n",
      "Vocab Examples : \n",
      "\t [UNK] 0\n",
      "\t [PAD] 1\n",
      "\t the 2\n",
      "\t and 3\n",
      "\t a 4\n",
      "\t of 5\n",
      "\t to 6\n",
      "\t is 7\n",
      "\t in 8\n",
      "\t it 9\n",
      "---------------------------------\n",
      "Label Size : 2\n",
      "Lable Examples : \n",
      "\t neg 0\n",
      "\t pos 1\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary Info\n",
    "print(f'Vocab Size : {len(TEXT.vocab)}')\n",
    "\n",
    "print('Vocab Examples : ')\n",
    "for idx, (k, v) in enumerate(TEXT.vocab.stoi.items()):\n",
    "    if idx >= 10:\n",
    "        break    \n",
    "    print('\\t', k, v)\n",
    "\n",
    "print('---------------------------------')\n",
    "\n",
    "# Label Info\n",
    "print(f'Label Size : {len(LABEL.vocab)}')\n",
    "\n",
    "print('Lable Examples : ')\n",
    "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n",
    "    print('\\t', k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1592903455887,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "s7dLNrxJMmEF",
    "outputId": "e102b9b7-beb6-4c2a-f27a-c0f75cb17bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51956, 300])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check embedding vectors\n",
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuSh9SlQLfGp"
   },
   "source": [
    "## Spliting Validation Data & Making Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbH-Rha8___V"
   },
   "outputs": [],
   "source": [
    "# Spliting Valid set\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(0),\n",
    "                                          split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKOfVNAwAJLU"
   },
   "outputs": [],
   "source": [
    "model_config['batch_size'] = 30\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=model_config['batch_size'],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9903,
     "status": "ok",
     "timestamp": 1592903464561,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "8OFTE-xAwJYb",
    "outputId": "14d28cc2-d8ad-45e4-9dbc-f87411af7d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 30]\n",
      "\t[.text]:[torch.cuda.LongTensor of size 30x500 (GPU 0)]\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 30 (GPU 0)]\n",
      "tensor([[    1,     1,     1,  ...,  1262,    22,   119],\n",
      "        [    1,     1,     1,  ...,  5769,     3,  4838],\n",
      "        [    1,     1,     1,  ...,  3035,    76,  4462],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ..., 15469,  5258,     0],\n",
      "        [    1,     1,     1,  ...,    16,   916,   467],\n",
      "        [    1,     1,     1,  ...,    24,   233,  2630]], device='cuda:0')\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check batch data\n",
    "sample_for_check = next(iter(train_iterator))\n",
    "print(sample_for_check)\n",
    "print(sample_for_check.text)\n",
    "print(sample_for_check.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9891,
     "status": "ok",
     "timestamp": 1592903464562,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "NU1fESnXyR9E",
    "outputId": "49a58843-8f07-4c0c-f7b8-47a6ad1813b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will never forget the wit and great comedy of the original vacation movie the lines pacing and timing of events in that film are outstanding however this european vacation sequel is a major let down in this sequel the griswalds win a european vacation on a game show the problem is that many of the jokes in the film are little more than mild ha ha laughs for example a flight attendant on an airplane asks clark do you want your coke in the can clark answers back no i'll have it right here that's really about the only line that is funny in this film european vacation's humor is strained as if the writers borrowed all the jokes from the first movie tried to re hash a script that had been done before and relied on a ridiculous slap stick chase scene sequence toward the end of the picture just to kill time worse the natural comic standouts like randy quaid as cousin eddie and the original kids who played rusty and audrey from the first movie so well are nowhere to be found their replacements are not funny can't act and just look like they are going through the motions most of the time there are also a few crude sex jokes and comments that are not only not funny they are in bad taste the should have stayed in wally world the place that made them legends don't join them on this european dreadful adventure viewers should re watch the original vacation movie in place of this you'll be glad you did\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "# Check reverting data\n",
    "print(' '.join([TEXT.vocab.itos[int(x)] for x in sample_for_check.text[0,:] if x not in [0,1]]))\n",
    "print(LABEL.vocab.itos[int(sample_for_check.label[0])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZXWakE7MxU8"
   },
   "source": [
    "## Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CD2AK0NMAKr1"
   },
   "outputs": [],
   "source": [
    "class SentenceClassification(nn.Module):\n",
    "    def __init__(self, **model_config):\n",
    "        super(SentenceClassification, self).__init__()\n",
    "\n",
    "        if model_config['emb_type'] == 'glove' or 'fasttext':\n",
    "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
    "                                    model_config['emb_dim'],\n",
    "                                    _weight = TEXT.vocab.vectors)\n",
    "        else:\n",
    "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
    "                                    model_config['emb_dim'])\n",
    "        \n",
    "        self.bidirectional = model_config['bidirectional']\n",
    "        self.num_direction = 2 if model_config['bidirectional'] else 1\n",
    "        self.model_type = model_config['model_type'] \n",
    "\n",
    "        self.RNN = nn.RNN (input_size = model_config['emb_dim'],\n",
    "                           hidden_size = model_config['hidden_dim'],\n",
    "                           dropout=model_config['dropout'],\n",
    "                           bidirectional = model_config['bidirectional'],\n",
    "                           batch_first = model_config['batch_first'])\n",
    "        \n",
    "        self.LSTM= nn.LSTM(input_size = model_config['emb_dim'],\n",
    "                           hidden_size = model_config['hidden_dim'],\n",
    "                           dropout=model_config['dropout'],\n",
    "                           bidirectional = model_config['bidirectional'],\n",
    "                           batch_first = model_config['batch_first'])\n",
    "        \n",
    "        self.GRU = nn.GRU (input_size = model_config['emb_dim'],\n",
    "                           hidden_size = model_config['hidden_dim'],\n",
    "                           dropout=model_config['dropout'],\n",
    "                           bidirectional = model_config['bidirectional'],\n",
    "                           batch_first = model_config['batch_first'])\n",
    "    \n",
    "        self.fc = nn.Linear(model_config['hidden_dim'] * self.num_direction,\n",
    "                            model_config['output_dim'])\n",
    "        \n",
    "        self.drop = nn.Dropout(model_config['dropout'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        emb = self.emb(x) \n",
    "        # emb : (Batch_Size, Max_Seq_Length, Emb_dim)\n",
    "\n",
    "        if self.model_type == 'RNN':\n",
    "            output, hidden = self.RNN(emb) \n",
    "        elif self.model_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.LSTM(emb)\n",
    "        elif self.model_type == 'GRU':\n",
    "            output, hidden = self.GRU(emb)\n",
    "        else:\n",
    "            raise NameError('Select model_type in [RNN, LSTM, GRU]')\n",
    "        \n",
    "        # output : (Batch_Size, Max_Seq_Length, Hidden_dim * num_direction) \n",
    "        # hidden : (num_direction, Batch_Size, Hidden_dim)\n",
    "        \n",
    "        last_output = output[:,-1,:]\n",
    "\n",
    "        # last_output : (Batch_Size, Hidden_dim * num_direction)\n",
    "        return self.fc(self.drop(last_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_3DNQR3M30p"
   },
   "source": [
    "### Checking feed-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8676uoMayZWm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3VJ5BuHkm-4"
   },
   "outputs": [],
   "source": [
    "model_config.update(dict(batch_first = True,\n",
    "                         model_type = 'RNN',\n",
    "                         bidirectional = True,\n",
    "                         hidden_dim = 128,\n",
    "                         output_dim = 1,\n",
    "                         dropout = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWYjr7KQZxXu"
   },
   "outputs": [],
   "source": [
    "model = SentenceClassification(**model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhGNULElZuI_"
   },
   "outputs": [],
   "source": [
    "predictions = model.forward(sample_for_check.text).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wabzuaD1AKjF"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdOXGw9ze-lI"
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(predictions, sample_for_check.label)\n",
    "acc = binary_accuracy(predictions, sample_for_check.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10106,
     "status": "ok",
     "timestamp": 1592903464814,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "s5OBri4AsPVy",
    "outputId": "85ab47d2-903a-489b-d845-f74ef20a7e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1991, -0.2183, -0.0567,  0.0383,  0.1517,  0.1715,  0.0074,  0.1285,\n",
      "         0.0496,  0.0986,  0.1914,  0.0907,  0.0655,  0.2261,  0.0812,  0.2469,\n",
      "         0.0252,  0.0782,  0.2184,  0.1788, -0.1360,  0.0331,  0.2985,  0.1957,\n",
      "         0.0576,  0.1593,  0.2175,  0.0902, -0.0866, -0.1227], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "tensor(0.7202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) tensor(0.4000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rswNBOAzoImC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCgs1fdcAKXF"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, loss_fn, idx_epoch, **model_params):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train() \n",
    "    batch_size = model_params['batch_size']\n",
    "\n",
    "    for idx, batch in enumerate(iterator):\n",
    "        \n",
    "        # Initializing\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward \n",
    "        predictions = model(batch.text).squeeze()\n",
    "        loss = loss_fn(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        sys.stdout.write(\n",
    "                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n",
    "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
    "                    f\"  Loss: {loss.item():.4}\"\\\n",
    "                    f\"  Acc : {acc.item():.4}\"\\\n",
    "                    )\n",
    "\n",
    "        # Backward \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update Epoch Performance\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator) , epoch_acc/len(iterator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zqJ1gkFARwp"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, loss_fn):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = loss_fn(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIA_7QQzoLK1"
   },
   "source": [
    "### bi-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6GtVuVFUHqz"
   },
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'RNN'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 318790,
     "status": "ok",
     "timestamp": 1592903783645,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "uTvlbDLnUHq2",
    "outputId": "fe52341b-63f0-49ab-b088-097cf18060a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : bi-RNN_glove\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.7751  Acc : 0.5667\n",
      "\t Saved at 0-epoch\n",
      "\t Epoch : 0 | Train Loss : 0.6075 | Train Acc : 0.6663\n",
      "\t Epoch : 0 | Valid Loss : 0.5847 | Valid Acc : 0.6918\n",
      "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.7125  Acc : 0.6667\n",
      "\t Saved at 1-epoch\n",
      "\t Epoch : 1 | Train Loss : 0.5057 | Train Acc : 0.7567\n",
      "\t Epoch : 1 | Valid Loss : 0.5764 | Valid Acc : 0.7152\n",
      "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.4595  Acc : 0.8667\n",
      "\t Epoch : 2 | Train Loss : 0.495 | Train Acc : 0.7576\n",
      "\t Epoch : 2 | Valid Loss : 0.582 | Valid Acc : 0.7038\n",
      "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.405  Acc : 0.89337\n",
      "\t Epoch : 3 | Train Loss : 0.4275 | Train Acc : 0.7985\n",
      "\t Epoch : 3 | Valid Loss : 0.6087 | Valid Acc : 0.7388\n",
      "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.5669  Acc : 0.6333\n",
      "\t Epoch : 4 | Train Loss : 0.3455 | Train Acc : 0.8483\n",
      "\t Epoch : 4 | Valid Loss : 0.7835 | Valid Acc : 0.616\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30044,
     "status": "ok",
     "timestamp": 1592904013732,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "akDRWiykUHq5",
    "outputId": "f1089f30-ec57-49ba-c78f-0f73f4f2d3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.5804 | Test Acc : 0.7061\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxG4rgwTo8D7"
   },
   "source": [
    "### bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpW7ui5mUBTk"
   },
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'LSTM'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 403700,
     "status": "ok",
     "timestamp": 1592904863046,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "CDN-nLxJUBTo",
    "outputId": "e6996ed9-0f51-4cdb-8d82-707602a82575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : bi-LSTM_glove\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.4761  Acc : 0.7333\n",
      "\t Saved at 0-epoch\n",
      "\t Epoch : 0 | Train Loss : 0.5165 | Train Acc : 0.7401\n",
      "\t Epoch : 0 | Valid Loss : 0.3516 | Valid Acc : 0.853\n",
      "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.2471  Acc : 0.96677\n",
      "\t Saved at 1-epoch\n",
      "\t Epoch : 1 | Train Loss : 0.2532 | Train Acc : 0.9011\n",
      "\t Epoch : 1 | Valid Loss : 0.2961 | Valid Acc : 0.8795\n",
      "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.1846  Acc : 0.96677\n",
      "\t Epoch : 2 | Train Loss : 0.0876 | Train Acc : 0.9719\n",
      "\t Epoch : 2 | Valid Loss : 0.4016 | Valid Acc : 0.8744\n",
      "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.0011  Acc : 1.0.077\n",
      "\t Epoch : 3 | Train Loss : 0.02934 | Train Acc : 0.9918\n",
      "\t Epoch : 3 | Valid Loss : 0.5356 | Valid Acc : 0.8707\n",
      "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.0007538  Acc : 1.07\n",
      "\t Epoch : 4 | Train Loss : 0.009912 | Train Acc : 0.9977\n",
      "\t Epoch : 4 | Valid Loss : 0.6288 | Valid Acc : 0.8673\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 430792,
     "status": "ok",
     "timestamp": 1592904894172,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "d8qjmPU7UBTq",
    "outputId": "3ad69658-a57d-4e05-87a9-cb5a7ea8f653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.3278 | Test Acc : 0.8627\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfDGBCWRxnB_"
   },
   "source": [
    "### bi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khyItx4zxnCA"
   },
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'GRU'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813897,
     "status": "ok",
     "timestamp": 1592905283205,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "om_7UjicxnCD",
    "outputId": "604af6c1-e459-42ac-892a-02077047d007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : bi-GRU_glove\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.1194  Acc : 0.93337\n",
      "\t Saved at 0-epoch\n",
      "\t Epoch : 0 | Train Loss : 0.4175 | Train Acc : 0.8047\n",
      "\t Epoch : 0 | Valid Loss : 0.2542 | Valid Acc : 0.896\n",
      "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.07329  Acc : 0.9667\n",
      "\t Epoch : 1 | Train Loss : 0.152 | Train Acc : 0.9441\n",
      "\t Epoch : 1 | Valid Loss : 0.2633 | Valid Acc : 0.8969\n",
      "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.02922  Acc : 1.0077\n",
      "\t Epoch : 2 | Train Loss : 0.03707 | Train Acc : 0.9887\n",
      "\t Epoch : 2 | Valid Loss : 0.3935 | Valid Acc : 0.8794\n",
      "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.0009991  Acc : 1.07\n",
      "\t Epoch : 3 | Train Loss : 0.008472 | Train Acc : 0.9981\n",
      "\t Epoch : 3 | Valid Loss : 0.4965 | Valid Acc : 0.8765\n",
      "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.0001015  Acc : 1.07\n",
      "\t Epoch : 4 | Train Loss : 0.003948 | Train Acc : 0.9992\n",
      "\t Epoch : 4 | Valid Loss : 0.7053 | Valid Acc : 0.877\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 842708,
     "status": "ok",
     "timestamp": 1592905313976,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "ZOL9MoBWxnCG",
    "outputId": "de53c613-9f09-476a-aa63-cd4f2120aa5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.261 | Test Acc : 0.8923\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEWK8wnkuEzA"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840929,
     "status": "ok",
     "timestamp": 1592905313977,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "x5VKyllQuReq",
    "outputId": "0188fc29-abeb-430e-8d45-71aa2e6ecef4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config['model_type'] = 'GRU'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "model.load_state_dict(torch.load(f\"./{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPifO6k5ugGG"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    indexed = TEXT.numericalize(TEXT.pad([TEXT.tokenize(PreProcessingText(sentence))]))\n",
    "    input_data = torch.LongTensor(indexed).to(device)\n",
    "    prediction = torch.sigmoid(model(input_data))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 839339,
     "status": "ok",
     "timestamp": 1592905313978,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "gY4lDbr-xB7V",
    "outputId": "27f24a58-c4fa-449b-aad5-ac854af7206e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851792454719543"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'this movie is FUN'\n",
    "predict_sentiment(model = model, sentence = test_sentence)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOy1P9YE87rAnMUJGk7bwbH",
   "collapsed_sections": [],
   "name": "6-3_model_imdb_glove.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
