{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2954,
     "status": "ok",
     "timestamp": 1593391576630,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "CoHYrwC67EL8",
    "outputId": "59abe359-5c45-4009-9ab5-3d75c851726e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 29 00:46:14 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Colab을 이용할 경우, GPU 사용을 위해 \"런타임 - 런타임 유형 변경 - GPU 설정\" 후 실행\n",
    "\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4317,
     "status": "ok",
     "timestamp": 1593391584152,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "qOJHc07KtoNX",
    "outputId": "77298cc3-9282-42ca-b85f-df1f1abab461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hx5TJjks6U6T"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2036,
     "status": "ok",
     "timestamp": 1593391590558,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "gc-TxG93iYiw",
    "outputId": "2bd3a2c9-5774-4070-c841-2ee5fdff4837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'dog', 'is', 'cute', '.', 'he', 'likes', 'playing', '.', 'i', 'bought', 'a', 'pet', 'food', 'for', 'him']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sentence = \"My dog is cute. He likes playing. I bought a  pet food for him\"\n",
    "# sentence = '나는 책상 위에 사과를 먹었다. 알고 보니 그 사과는 Jason 것이었다. 그래서 Jason에게 사과를 했다'\n",
    "print(tokenizer.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1593391591090,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "OQHxkXh3vdxv",
    "outputId": "4d2ab5d9-fcda-41d8-b75d-2526174864f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1593391592345,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "USbg3E6w6oWw",
    "outputId": "73a76cea-4085-42c4-fa3a-3d63d964bac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)\n",
    "\n",
    "def new_tokenizer(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1024,
     "status": "ok",
     "timestamp": 1593391594966,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "dOYr6sI59iAJ"
   },
   "outputs": [],
   "source": [
    "def PreProcessingText(input_sentence):\n",
    "    input_sentence = input_sentence.lower() # 소문자화\n",
    "    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n",
    "    input_sentence = re.sub('[!\"$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n",
    "    input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n",
    "    if input_sentence:\n",
    "        return input_sentence\n",
    "\n",
    "def PreProc(list_sentence):\n",
    "    return [tokenizer.convert_tokens_to_ids(PreProcessingText(x)) for x in list_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1593391598597,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "SutCsHFF7heb"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = new_tokenizer,\n",
    "                  preprocessing = PreProc,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 234595,
     "status": "ok",
     "timestamp": 1593391834277,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "XpfeA6uR7vNf"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 231474,
     "status": "ok",
     "timestamp": 1593391834278,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "3A2QD6Lr8AnV"
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 230971,
     "status": "ok",
     "timestamp": 1593391834279,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "GESZjdyn9Nxc"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state = random.seed(0), split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3O6ttcHKrIq"
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1593391835298,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "34DoliQ6mdob",
    "outputId": "22e0e598-078a-4ffb-e9fd-35397eb6eda1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Length : 20000\n",
      "Test Data Length : 25000\n"
     ]
    }
   ],
   "source": [
    "# Data Length\n",
    "print(f'Train Data Length : {len(train_data.examples)}')\n",
    "print(f'Test Data Length : {len(test_data.examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1470,
     "status": "ok",
     "timestamp": 1593391835772,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "3UNJJZE0mH75",
    "outputId": "9e721e36-93b0-4cd7-dacd-342ae6439250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x2b63166b9e8>,\n",
       " 'label': <torchtext.data.field.LabelField at 0x2b63166bc18>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Fields\n",
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1455,
     "status": "ok",
     "timestamp": 1593391835773,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "ViUZ13AM_HFQ",
    "outputId": "04f1f426-aee1-4aa0-f6bd-9845f8799fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Data Sample ----\n",
      "Input : \n",
      "['another', 'in', 'a', 'long', 'line', 'of', 'flick', '##s', 'made', 'by', 'people', 'who', 'think', 'that', 'knowing', 'how', 'to', 'operate', 'a', 'camera', 'is', 'the', 'same', 'as', 'telling', 'a', 'story', '[UNK]', 'within', '15', 'minutes', '[UNK]', 'the', 'entire', 'premise', 'is', 'laid', 'out', 'in', 'just', 'a', 'few', 'lines', '[UNK]', 'so', 'there', 'is', 'absolutely', 'no', 'mystery', '[UNK]', 'which', 'eliminate', '##s', 'a', 'whole', 'face', '##t', 'of', 'the', 'suspense', '[UNK]', 'the', 'only', 'half', '[UNK]', 'way', 'competent', 'actor', 'is', 'killed', '10', 'minutes', 'into', 'the', 'film', '[UNK]', 'so', 'we', \"'\", 're', 'left', 'with', 'stupid', 'characters', 'running', 'around', 'doing', 'stupid', 'things', '[UNK]', 'low', 'budget', 'films', 'can', \"'\", 't', 'afford', 'expensive', 'special', 'effects', '[UNK]', 'so', 'the', 'c', '##gi', 'portions', 'are', 'un', '##sur', '##pr', '##ising', '##ly', 'un', '##im', '##pressive', '[UNK]', 'but', 'were', 'at', 'least', 'a', 'valid', 'attempt', '[UNK]', 'the', 'creature', 'suit', 'is', 'terrible', '[UNK]', 'as', 'seen', 'when', 'it', 'falls', 'to', 'the', 'sidewalk', '[UNK]', 'and', 'the', 'director', 'keeps', 'emphasizing', 'the', 'eyes', '[UNK]', 'which', 'aren', \"'\", 't', 'even', 'the', 'red', 'color', 'shown', 'in', 'mirror', 'shots', '[UNK]', 'the', 'dialogue', 'is', 'clumsy', 'and', 'un', '##ins', '##pired', '[UNK]', 'with', 'some', 'lines', 'reminiscent', 'of', 'aliens', 'or', 'term', '##inator', '[UNK]', 'the', 'last', 'action', 'sequence', 'takes', 'place', 'in', 'a', 'police', 'station', '[UNK]', 'also', 'a', 'rip', '[UNK]', 'off', 'from', 'term', '##inator', '[UNK]', 'with', 'everyone', 'hiding', 'in', 'the', 'one', 'glass', 'lined', 'office', 'that', 'the', 'dark', '##wo', '##lf', 'doesn', \"'\", 't', 'smash', 'into', '[UNK]', 'in', 'the', 'end', '[UNK]', 'the', 'girl', 'calls', 'the', 'hero', '[UNK]', 'a', 'good', 'protector', '[UNK]', '[UNK]', 'but', 'he', 'gets', 'both', 'his', 'partners', '[UNK]', 'the', 'original', 'protector', '[UNK]', 'and', 'at', 'least', 'three', 'other', 'civilians', '[UNK]', 'not', 'to', 'mention', 'a', 'dozen', 'cops', '[UNK]', 'all', 'killed', 'without', 'getting', 'a', 'decent', 'shot', 'off', '[UNK]', 'in', 'spite', 'of', 'an', 'arsenal', 'of', 'silver', 'bullets', 'and', 'a', 'sub', '##mac', '##hine', 'gun', '[UNK]', 'but', 'here', \"'\", 's', 'the', 'real', 'clinch', '##er', 'for', 'bad', 'writing', '[UNK]', 'they', 'could', 'have', 'killed', 'the', 'beast', 'right', 'after', 'the', 'beginning', 'credits', 'when', 'it', 'was', 'holding', 'the', 'strip', '##per', 'while', 'flashing', 'its', 'red', 'eyes', '[UNK]', 'instead', '[UNK]', 'they', 'took', 'it', 'into', 'custody', '[UNK]', '[UNK]', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "# Data Sample\n",
    "print('---- Data Sample ----')\n",
    "print('Input : ')\n",
    "print(tokenizer.convert_ids_to_tokens(vars(train_data.examples[2])['text']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pn4ddGIQLL_u"
   },
   "source": [
    "## Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSucMR06LR8Y"
   },
   "source": [
    "## Making Vocab & Setting Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1445,
     "status": "ok",
     "timestamp": 1593391835774,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "vt7ulofTn6U4",
    "outputId": "bb8737c6-265a-4a53-ad58-c719bbab07c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Size : 2\n",
      "Lable Examples : \n",
      "\t neg 0\n",
      "\t pos 1\n"
     ]
    }
   ],
   "source": [
    "# Label Info\n",
    "print(f'Label Size : {len(LABEL.vocab)}')\n",
    "\n",
    "print('Lable Examples : ')\n",
    "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n",
    "    print('\\t', k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuSh9SlQLfGp"
   },
   "source": [
    "## Spliting Validation Data & Making Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1436,
     "status": "ok",
     "timestamp": 1593391835775,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "FeptM8GxAR3v"
   },
   "outputs": [],
   "source": [
    "model_config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1427,
     "status": "ok",
     "timestamp": 1593391835775,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "LKOfVNAwAJLU"
   },
   "outputs": [],
   "source": [
    "model_config['batch_size'] = 8\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=model_config['batch_size'],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5811,
     "status": "ok",
     "timestamp": 1593391840166,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "LpMNsdroSpCe",
    "outputId": "afe80633-b7e7-4293-d293-65ee1ea7c0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 8]\n",
      "\t[.text]:[torch.cuda.LongTensor of size 8x512 (GPU 0)]\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 8 (GPU 0)]\n",
      "tensor([[ 101, 5752, 7104,  ...,    0,    0,    0],\n",
      "        [ 101,  100, 8334,  ...,    0,    0,    0],\n",
      "        [ 101, 1053,  100,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1996, 2143,  ...,    0,    0,    0],\n",
      "        [ 101, 4931, 2065,  ...,    0,    0,    0],\n",
      "        [ 101, 2023, 3185,  ...,    0,    0,    0]], device='cuda:0')\n",
      "tensor([1., 1., 1., 0., 0., 0., 0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check batch data\n",
    "sample_for_check = next(iter(train_iterator))\n",
    "print(sample_for_check)\n",
    "print(sample_for_check.text)\n",
    "print(sample_for_check.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZXWakE7MxU8"
   },
   "source": [
    "## Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3623,
     "status": "ok",
     "timestamp": 1593394252671,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "pnfDdpS08r3J"
   },
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8427,
     "status": "ok",
     "timestamp": 1593391842801,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "jONbzMNmoI5e"
   },
   "outputs": [],
   "source": [
    "model_config['emb_dim'] = bert.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8420,
     "status": "ok",
     "timestamp": 1593391842802,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "97tbUwK37XvO",
    "outputId": "affa75f9-af3d-4d29-d326-c5daa238a9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(model_config['emb_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8414,
     "status": "ok",
     "timestamp": 1593391842803,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "CD2AK0NMAKr1"
   },
   "outputs": [],
   "source": [
    "class SentenceClassification(nn.Module):\n",
    "    def __init__(self, **model_config):\n",
    "        super(SentenceClassification, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.fc = nn.Linear(model_config['emb_dim'],\n",
    "                            model_config['output_dim'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pooled_cls_output = self.bert(x)[1]\n",
    "        return self.fc(pooled_cls_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rswNBOAzoImC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8405,
     "status": "ok",
     "timestamp": 1593391842803,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "WCgs1fdcAKXF"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, loss_fn, idx_epoch, **model_params):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train() \n",
    "    batch_size = model_params['batch_size']\n",
    "\n",
    "    for idx, batch in enumerate(iterator):\n",
    "        \n",
    "        # Initializing\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward \n",
    "        predictions = model(batch.text).squeeze()\n",
    "        loss = loss_fn(predictions, batch.label)\n",
    "\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        sys.stdout.write(\n",
    "                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n",
    "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
    "                    f\"  Loss: {loss.item():.4}\"\\\n",
    "                    f\"  Acc : {acc.item():.4}\"\\\n",
    "                    )\n",
    "\n",
    "        # Backward \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update Epoch Performance\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator) , epoch_acc/len(iterator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1190,
     "status": "ok",
     "timestamp": 1593394055907,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "3zqJ1gkFARwp"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, loss_fn, idx_epoch, **model_params):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    batch_size = model_params['batch_size']\n",
    "    \n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(iterator):\n",
    "            predictions = model(batch.text).squeeze()\n",
    "            loss = loss_fn(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "            sys.stdout.write(\n",
    "                    \"\\r\" + f\"[Eval] Epoch : {idx_epoch:^3}\"\\\n",
    "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
    "                    f\"  Loss: {loss.item():.4}\"\\\n",
    "                    f\"  Acc : {acc.item():.4}\"\\\n",
    "                    )\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIA_7QQzoLK1"
   },
   "source": [
    "### bi-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8352,
     "status": "ok",
     "timestamp": 1593391842804,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "Ih82kU5OOlGK"
   },
   "outputs": [],
   "source": [
    "model_config.update(dict(output_dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1335,
     "status": "ok",
     "timestamp": 1593394271894,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "n6GtVuVFUHqz"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    # rounded_preds = torch.argmax(preds, axis=1) \n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "model = SentenceClassification(**model_config)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8293,
     "status": "ok",
     "timestamp": 1593391842805,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "bpELIoOm468K",
    "outputId": "6ce8ae6b-d6a9-4f69-d91c-55b9b7e43067"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109483009"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9081421,
     "status": "ok",
     "timestamp": 1593403354389,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "uTvlbDLnUHq2",
    "outputId": "8de04fe5-508f-4127-9e31-7d776b29777b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : BERT\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20000 / 20000 (100.0%)]  Loss: 0.0814  Acc : 1.075\n",
      "\t Epoch : 0 | Train Loss : 0.3003 | Train Acc : 0.8651\n",
      "[Eval] Epoch :  0 [5000 / 5000 (100.0%)]  Loss: 0.2644  Acc : 0.875\n",
      "\t Epoch : 0 | Valid Loss : 0.2061 | Valid Acc : 0.9166\n",
      "\t Model is saved at 0-epoch\n",
      "[Train] Epoch :  1 [20000 / 20000 (100.0%)]  Loss: 0.06414  Acc : 1.055\n",
      "\t Epoch : 1 | Train Loss : 0.1619 | Train Acc : 0.9413\n",
      "[Eval] Epoch :  1 [5000 / 5000 (100.0%)]  Loss: 0.1703  Acc : 1.075\n",
      "\t Epoch : 1 | Valid Loss : 0.1944 | Valid Acc : 0.928\n",
      "\t Model is saved at 1-epoch\n",
      "[Train] Epoch :  2 [20000 / 20000 (100.0%)]  Loss: 0.01884  Acc : 1.005\n",
      "\t Epoch : 2 | Train Loss : 0.09785 | Train Acc : 0.9665\n",
      "[Eval] Epoch :  2 [5000 / 5000 (100.0%)]  Loss: 0.1581  Acc : 0.8755\n",
      "\t Epoch : 2 | Valid Loss : 0.2447 | Valid Acc : 0.9246\n",
      "[Train] Epoch :  3 [20000 / 20000 (100.0%)]  Loss: 0.001591  Acc : 1.05\n",
      "\t Epoch : 3 | Train Loss : 0.06446 | Train Acc : 0.9799\n",
      "[Eval] Epoch :  3 [5000 / 5000 (100.0%)]  Loss: 0.004881  Acc : 1.0\n",
      "\t Epoch : 3 | Valid Loss : 0.296 | Valid Acc : 0.9272\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 4\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = \"BERT\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    print('')\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn, epoch, **model_config)\n",
    "    print('')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')\n",
    "    # print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Model is saved at {epoch}-epoch')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 485078,
     "status": "ok",
     "timestamp": 1593404027237,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "LDu05XqjiR5k",
    "outputId": "59590bea-6c02-489c-8cf3-a8b7f7b4c803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Epoch :  0 [25000 / 25000 (100.0%)]  Loss: 1.64  Acc : 0.5.8755\n",
      "Test Loss : 0.2876 | Test Acc : 0.9248\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "# model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "epoch = 0\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn, epoch, **model_config)\n",
    "print('')\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498117,
     "status": "ok",
     "timestamp": 1593404555182,
     "user": {
      "displayName": "seongsu bang",
      "photoUrl": "",
      "userId": "06124410414614761416"
     },
     "user_tz": -540
    },
    "id": "akDRWiykUHq5",
    "outputId": "3dcf88c5-f555-4638-9512-5b7d5a06c353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Epoch :  0 [25000 / 25000 (100.0%)]  Loss: 0.6764  Acc : 0.6255\n",
      "Test Loss : 0.1905 | Test Acc : 0.9264\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "epoch = 0\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn, epoch, **model_config)\n",
    "print('')\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMrI0DH71x15rcKSbGnP/HW",
   "collapsed_sections": [],
   "name": "6-5_model_imdb_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
